# Bug: ML Pipeline (Topics + NER) cassÃ© en production

## Statut
- [ ] En cours d'investigation
- [x] En cours de correction (date: 2026-02-15)
- [ ] CorrigÃ© â€” en attente vÃ©rification post-deploy numpy

## SÃ©vÃ©ritÃ©
- ğŸ”´ Critique (source sync cassÃ©, ML worker bloquÃ©)

## Description

Le deploy de la branche `fix/ml-pipeline-topics-ner` (PR #77, squash merge `aa6a942`) a introduit 3 bugs qui cassent le ML pipeline ET le source sync en production.

**Impact observÃ©:**
- Source sync: 206/207 sources en Ã©chec (toute la synchro RSS cassÃ©e)
- ML worker: traite des batches mais 100% des items Ã©chouent
- Queue stats dÃ©gradÃ©s: failed=1097, completed=14, success_rate=1.34%

---

## Bugs identifiÃ©s (3)

### Bug 1: Colonne `entities` dans l'ORM mais absente en DB
**SÃ©vÃ©ritÃ©:** ğŸ”´ Critique
**Commit fix:** `b80cabc`
**Status:** âœ… DÃ©ployÃ© et fixÃ©

**Cause racine:**
Le squash merge PR #77 a inclus le commit qui rÃ©activait `Content.entities` dans l'ORM (`167d372`) mais a **perdu** le commit qui le re-commentait (`d1c6134`). Seul le fichier migration a Ã©tÃ© modifiÃ© dans le merge (1 file changed), pas `content.py`.

RÃ©sultat: SQLAlchemy gÃ©nÃ¨re `SELECT ... contents.entities ...` sur toute query Content, mais la colonne n'existe pas en DB â†’ `ProgrammingError: UndefinedColumn` sur TOUTES les queries.

**Solution:** Re-commenter `entities` dans `packages/api/app/models/content.py` ligne 67.

**Fichiers concernÃ©s:**
- `packages/api/app/models/content.py`

---

### Bug 2: Lazy-loading async â†’ MissingGreenlet
**SÃ©vÃ©ritÃ©:** ğŸ”´ Critique
**Commit fix:** `4018058`
**Status:** âœ… DÃ©ployÃ© et fixÃ©

**Cause racine:**
Le worker accÃ¨de `item.content` (relationship lazy-loaded) et `content.source` dans un contexte async SQLAlchemy. En mode async, le lazy-loading synchrone lÃ¨ve `MissingGreenlet` (greenlet_spawn not called). L'exception est attrapÃ©e silencieusement par le worker et l'item est marquÃ© `failed` sans log d'erreur visible.

**Solution:** Remplacer les accÃ¨s lazy par des chargements explicites async:
```python
# Avant (crash MissingGreenlet):
content = item.content
# ...
topics = content.source.granular_topics or []

# AprÃ¨s (chargement async explicite):
content = await session.get(Content, item.content_id)
source = await session.get(Source, content.source_id) if content.source_id else None
# ...
topics = source.granular_topics or []
```

**Fichiers concernÃ©s:**
- `packages/api/app/workers/classification_worker.py`

---

### Bug 3: numpy manquant â†’ mDeBERTa classification Ã©choue
**SÃ©vÃ©ritÃ©:** ğŸŸ  Haute (fallback fonctionne)
**Commit fix:** `5a7304c`
**Status:** â³ PushÃ©, en attente deploy + vÃ©rification

**Cause racine:**
`numpy` n'est pas listÃ© explicitement dans `requirements-ml.txt`. Il est une dÃ©pendance indirecte de `torch`/`transformers`, mais sur l'image Docker slim Python 3.12, la rÃ©solution pip peut ne pas l'installer correctement.

Le modÃ¨le mDeBERTa se charge (lazy imports) mais Ã©choue Ã  l'infÃ©rence avec `"Numpy is not available"`. Le worker tombe en fallback sur `source.granular_topics`.

**Solution:** Ajouter `numpy>=1.26.0,<2.0` en tÃªte de `requirements-ml.txt`.

**Fichiers concernÃ©s:**
- `packages/api/requirements-ml.txt`

---

## Ã‰tapes de reproduction
1. DÃ©ployer le merge `aa6a942` (PR #77) sur Railway
2. Observer les logs: `column contents.entities does not exist` sur toutes les queries
3. Queue stats: `failed` monte, `completed` stagne, source sync cassÃ©

---

## VÃ©rification post-deploy

### Checklist agent suivant

AprÃ¨s deploy du commit `5a7304c` (numpy fix):

```bash
# 1. VÃ©rifier le commit dÃ©ployÃ©
railway logs --service Facteur 2>&1 | grep "commit_sha"
# Attendu: commit_sha="5a7304c" (ou plus rÃ©cent)

# 2. VÃ©rifier absence d'erreurs entities
railway logs --service Facteur 2>&1 | grep "UndefinedColumn"
# Attendu: aucun rÃ©sultat

# 3. VÃ©rifier absence d'erreurs MissingGreenlet
railway logs --service Facteur 2>&1 | grep -i "greenlet\|MissingGreenlet"
# Attendu: aucun rÃ©sultat

# 4. VÃ©rifier que numpy est rÃ©solu
railway logs --service Facteur 2>&1 | grep "Numpy is not available"
# Attendu: aucun rÃ©sultat (si numpy fix dÃ©ployÃ©)

# 5. VÃ©rifier chargement du modÃ¨le mDeBERTa
railway logs --service Facteur 2>&1 | grep "classification_service.model_loaded"
# Attendu: prÃ©sent (si ML_ENABLED=true sur Railway)

# 6. VÃ©rifier que le worker traite des batches
railway logs --service Facteur 2>&1 | grep "classification_worker.processing_batch"
# Attendu: batches rÃ©guliers toutes les ~60s

# 7. Queue stats
curl -s https://facteur-production.up.railway.app/api/internal/admin/queue-stats | python3 -m json.tool
# Attendu: completed en hausse, 0 new failures, success_rate > 50%

# 8. VÃ©rifier qu'un article a des topics
# Via Supabase Dashboard > Table contents > Filter: topics IS NOT NULL
# Attendu: articles rÃ©cemment classifiÃ©s avec topics non-vides
```

### Variable d'environnement Railway

VÃ©rifier que `ML_ENABLED=true` est configurÃ© sur Railway:
```bash
railway variables --service Facteur | grep ML_ENABLED
```
Si absent ou `false`, le classifier mDeBERTa ne chargera pas. Le worker fonctionnera quand mÃªme en fallback (source topics), mais sans la classification ML fine.

---

## Supabase: migration `entities` column

### Contexte
La colonne `contents.entities` (TEXT[] + GIN index) ne peut pas Ãªtre crÃ©Ã©e sur le tier gratuit Supabase (timeout ALTER TABLE sur table volumineuse ~35k rows).

### Options pour crÃ©er la colonne

| Option | Description | Recommandation |
|--------|-------------|----------------|
| **A** | Upgrade Supabase Pro (25$/mois) | âœ… RecommandÃ© si budget OK |
| **B** | `ALTER TABLE` via Supabase Dashboard SQL Editor (pas de timeout CLI) | âš ï¸ Tester d'abord |
| **C** | CrÃ©er via `CREATE INDEX CONCURRENTLY` (non-bloquant) | âœ… Si option B timeout |
| **D** | Table sÃ©parÃ©e `content_entities` | âŒ Sur-complexe pour le besoin |

### ProcÃ©dure recommandÃ©e (Option B ou C)

```sql
-- Ã‰tape 1: Ajouter la colonne (rapide, ~1s mÃªme sur grosse table)
ALTER TABLE contents ADD COLUMN IF NOT EXISTS entities TEXT[];

-- Ã‰tape 2: CrÃ©er l'index (peut Ãªtre lent, utiliser CONCURRENTLY)
CREATE INDEX CONCURRENTLY IF NOT EXISTS ix_contents_entities
ON contents USING gin (entities);
```

**AprÃ¨s la migration SQL:**
1. DÃ©-commenter `entities` dans `packages/api/app/models/content.py` ligne 67
2. Mettre la migration `p1q2r3s4t5u6` en mode actif (remplacer `pass` par le vrai DDL)
3. Commit + push + deploy
4. VÃ©rifier: `railway logs | grep "entities_column_missing"` â†’ aucun rÃ©sultat
5. MAJ `docs/maintenance/maintenance-ner-disabled.md` â†’ status "RÃ©activÃ©"

---

## Fichiers concernÃ©s (tous commits)

| Fichier | Commit | Changement |
|---------|--------|------------|
| `packages/api/app/models/content.py` | `b80cabc` | Re-commenter `entities` |
| `packages/api/app/workers/classification_worker.py` | `4018058` | Fix async lazy-loading |
| `packages/api/requirements-ml.txt` | `5a7304c` | Ajouter numpy explicite |

## Timeline

| Heure (UTC) | Ã‰vÃ©nement |
|-------------|-----------|
| ~18:30 | Deploy PR #77 (`aa6a942`) â€” production cassÃ©e |
| 18:36 | Erreurs `UndefinedColumn` massives, source sync 206/207 failed |
| 18:49 | Deploy hotfix entities (`b80cabc`) â€” source sync restaurÃ© |
| 18:49-19:07 | Worker traite mais 100% fail (lazy-loading async) |
| 19:11 | Deploy fix lazy-loading (`4018058`) â€” items commencent Ã  complÃ©ter |
| 19:15 | Push fix numpy (`5a7304c`) â€” en attente deploy |

## Notes

- Les 1097 items en `failed` ont `retry_count >= 3` et ne seront pas retentÃ©s automatiquement. Un reset manuel peut Ãªtre nÃ©cessaire si on veut les retraiter:
  ```sql
  UPDATE classification_queue
  SET status = 'pending', retry_count = 0, error_message = NULL
  WHERE status = 'failed';
  ```
- Le backlog de ~33,800 items prendra ~56h au rythme actuel (10 items/min). ConsidÃ©rer augmenter `batch_size` dans le worker si les ressources Railway le permettent.
- La feature NER extrait des entitÃ©s mais ne les persiste pas (colonne absente). Voir `docs/maintenance/maintenance-ner-disabled.md`.
