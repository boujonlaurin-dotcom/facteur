# Story 10.7 : Table digest_completions + Logique Closure

## Status: Draft

## Story

**As a** système,  
**I want** persister les événements de closure dans une table dédiée,  
**so that** les métriques de succès puissent être calculées et le streak mis à jour.

## Acceptance Criteria

1. **Table `digest_completions`** créée pour tracker chaque closure
2. **Création automatique** d'un enregistrement à chaque closure
3. **Métriques capturées** : temps de complétion, articles lus/sauvegardés
4. **Déclenchement** du calcul de streak (Story 10.8)
5. **Unicité** : un seul enregistrement par (user_id, digest_date)

## Tasks / Subtasks

### Backend

- [ ] **Task 1: Migration déjà créée dans Story 10.1**
  - [x] La table `digest_completions` est créée par la migration de la Story 10.1
  - [x] Colonnes : `id`, `user_id`, `digest_date`, `completed_at`, `time_to_complete_seconds`, `articles_read`, `articles_saved`
  - [x] Contrainte UNIQUE sur `(user_id, digest_date)`
  - [x] Index pour requêtes de streak
  - [ ] **Action** : Vérifier que la migration inclut bien cette table

- [ ] **Task 2: Modèle déjà créé dans Story 10.1**
  - [x] Classe `DigestCompletion` créée dans `packages/api/app/models/daily_digest.py`
  - [ ] **Action** : Vérifier l'import dans `app/models/__init__.py`

- [ ] **Task 3: Implémenter la création à la closure**
  - [ ] Modifier `DigestService.action_item()` pour créer l'enregistrement
  - [ ] Compter articles_read et articles_saved depuis le digest
  - [ ] Calculer time_to_complete

- [ ] **Task 4: Créer le schéma Pydantic**
  - [ ] `DigestCompletionSchema` pour les réponses API

- [ ] **Task 5: Endpoint stats (optionnel)**
  - [ ] `GET /api/digest/stats` retourne l'historique des closures

## Dev Notes

### Schéma SQL

```sql
CREATE TABLE digest_completions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
    digest_date DATE NOT NULL,
    completed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    time_to_complete_seconds INT,
    articles_read INT NOT NULL DEFAULT 0,
    articles_saved INT NOT NULL DEFAULT 0,
    
    CONSTRAINT uq_digest_completion_user_date UNIQUE (user_id, digest_date)
);

CREATE INDEX idx_digest_completions_user_date 
ON digest_completions(user_id, digest_date DESC);

-- RLS
ALTER TABLE digest_completions ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own completions" ON digest_completions
    FOR SELECT USING (auth.uid() = user_id);
```

### Modèle SQLAlchemy

**Note** : Le modèle `DigestCompletion` est défini dans `packages/api/app/models/daily_digest.py` (créé par Story 10.1) :

```python
# packages/api/app/models/daily_digest.py

class DigestCompletion(Base):
    """Enregistrement d'une closure de digest."""
    
    __tablename__ = "digest_completions"
    __table_args__ = (
        Index("ix_digest_completions_user_date", "user_id", "digest_date"),
    )

    id: Mapped[UUID] = mapped_column(PGUUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id: Mapped[UUID] = mapped_column(PGUUID(as_uuid=True), nullable=False, index=True)
    digest_date: Mapped[date] = mapped_column(Date, nullable=False)
    completed_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), default=datetime.utcnow, nullable=False)
    
    # Metrics
    time_to_complete_seconds: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
    articles_read: Mapped[int] = mapped_column(Integer, nullable=False, default=0)
    articles_saved: Mapped[int] = mapped_column(Integer, nullable=False, default=0)
```

### Intégration dans DigestService

```python
# Modification dans packages/api/app/services/digest_service.py

from app.models.daily_digest import DigestCompletion


class DigestService:
    # ... (code existant) ...
    
    async def action_item(
        self, 
        user_id: UUID, 
        content_id: UUID, 
        action: str
    ) -> Optional[DigestActionResponse]:
        """Marque un item et crée la closure si nécessaire."""
        
        # ... (code existant jusqu'à la détection de closure) ...
        
        # Si closure détectée, créer l'enregistrement
        closure_triggered = was_pending and digest.is_complete
        time_to_complete = None
        
        if closure_triggered:
            time_to_complete = await self._create_completion_record(digest)
            
            # Trigger streak update (Story 10.8)
            await self._update_closure_streak(user_id, digest.digest_date)
        
        # ... (reste du code) ...
    
    async def _create_completion_record(self, digest: DailyDigest) -> int:
        """
        Crée un enregistrement de closure.
        
        Returns:
            Temps de complétion en secondes.
        """
        # Count read vs saved
        articles_read = sum(1 for item in digest.items if item["status"] == "read")
        articles_saved = sum(1 for item in digest.items if item["status"] == "saved")
        
        # Calculate time to complete
        time_to_complete = int(
            (digest.completed_at - digest.generated_at).total_seconds()
        )
        
        # Create record
        completion = DigestCompletion(
            user_id=digest.user_id,
            digest_date=digest.digest_date,
            completed_at=digest.completed_at,
            time_to_complete_seconds=time_to_complete,
            articles_read=articles_read,
            articles_saved=articles_saved,
        )
        
        self.session.add(completion)
        
        logger.info(
            "Digest completion recorded",
            user_id=str(digest.user_id),
            digest_date=str(digest.digest_date),
            time_seconds=time_to_complete,
            articles_read=articles_read,
            articles_saved=articles_saved,
        )
        
        return time_to_complete
    
    async def _update_closure_streak(self, user_id: UUID, completion_date: date):
        """
        Met à jour le streak de closure.
        Délégué à Story 10.8.
        """
        # Placeholder - implémenté dans Story 10.8
        pass
```

### Endpoint Stats (Optionnel)

```python
# Ajout dans packages/api/app/routers/digest_router.py

from app.schemas.digest import DigestStatsResponse


@router.get("/stats", response_model=DigestStatsResponse)
async def get_digest_stats(
    user_id: str = Depends(get_current_user),
    session: AsyncSession = Depends(get_session),
):
    """
    Retourne les statistiques de closure de l'utilisateur.
    """
    service = DigestService(session)
    return await service.get_user_stats(UUID(user_id))
```

```python
# Dans DigestService

async def get_user_stats(self, user_id: UUID) -> DigestStatsResponse:
    """Calcule les statistiques de closure."""
    from sqlalchemy import func
    
    # Total completions
    result = await self.session.execute(
        select(func.count(DigestCompletion.id))
        .where(DigestCompletion.user_id == user_id)
    )
    total_completions = result.scalar()
    
    # Average time to complete
    result = await self.session.execute(
        select(func.avg(DigestCompletion.time_to_complete_seconds))
        .where(DigestCompletion.user_id == user_id)
    )
    avg_time = result.scalar() or 0
    
    # Total articles read/saved
    result = await self.session.execute(
        select(
            func.sum(DigestCompletion.articles_read),
            func.sum(DigestCompletion.articles_saved)
        )
        .where(DigestCompletion.user_id == user_id)
    )
    row = result.fetchone()
    total_read = row[0] or 0
    total_saved = row[1] or 0
    
    return DigestStatsResponse(
        total_completions=total_completions,
        average_time_to_complete_seconds=int(avg_time),
        total_articles_read=total_read,
        total_articles_saved=total_saved,
    )
```

### Références Architecture

- [Source: models/daily_top3.py] — Pattern modèle existant
- [Source: 5.4.streak-quotidien.md] — Logique de streak existante

## Testing

- **Unit Tests** : `tests/services/test_digest_service.py`
  - Test création completion à la closure
  - Test comptage read/saved correct
  - Test calcul time_to_complete
  - Test unicité (user_id, digest_date)

## Definition of Done

- [ ] Table `digest_completions` créée
- [ ] Enregistrement créé automatiquement à la closure
- [ ] Métriques correctement calculées
- [ ] Tests passent

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 31/01/2026 | 1.0 | Création story | BMad Master |
