# Story 4.1d : Classification Articles (DistilBERT)

## Status: Done

## Story

**As a** syst√®me,  
**I want** classifier automatiquement chaque article par topics granulaires,  
**so that** le scoring soit pr√©cis m√™me si la source couvre plusieurs domaines.

## Acceptance Criteria

1. **Service `ClassificationService`** cr√©√© avec mod√®le CamemBERT
2. **Mod√®le ML h√©berg√©** sur Railway (~200MB RAM additionnel)
3. **Int√©gration pipeline sync RSS** : classification asynchrone, non-bloquante
4. **Latence** : Classification < 300ms par article
5. **Pr√©cision** : Valid√©e > 80% sur √©chantillon test (100 articles annot√©s)
6. **Fallback robuste** : Si service indisponible, h√©ritage `source.granular_topics`
7. **Nouvelle `ArticleTopicLayer`** int√©gr√©e au `ScoringEngine`

## Dev Notes

### Service de Classification

```python
# app/services/classification_service.py

from transformers import pipeline
from typing import List
import structlog

logger = structlog.get_logger()

class ClassificationService:
    """Service de classification ML pour tagger automatiquement les articles."""
    
    def __init__(self):
        self.classifier = pipeline(
            "zero-shot-classification",
            model="camembert/camembert-base-ccnet",
            device=-1  # CPU
        )
        
        # 50 labels en fran√ßais naturel
        self.candidate_labels = [
            "intelligence artificielle", "cryptomonnaie", "changement climatique",
            "justice sociale", "f√©minisme", "immigration", "sant√©", 
            "√©ducation", "urbanisme", "transition √©nerg√©tique",
            # ... 40 autres
        ]
        
        # Mapping label fran√ßais ‚Üí topic_slug
        self.label_to_slug = {
            "intelligence artificielle": "ai",
            "cryptomonnaie": "crypto",
            "changement climatique": "climate",
            # ... 50 mappings
        }
    
    def classify(
        self, 
        title: str, 
        description: str, 
        threshold: float = 0.3
    ) -> List[str]:
        """Classifie un article et retourne jusqu'√† 5 topic slugs."""
        try:
            # Limite tokens pour √©viter overhead
            text = f"{title}. {description[:500]}"
            
            result = self.classifier(
                text,
                self.candidate_labels,
                multi_label=True
            )
            
            topics = []
            for label, score in zip(result['labels'], result['scores']):
                if score > threshold and len(topics) < 5:
                    slug = self.label_to_slug.get(label)
                    if slug:
                        topics.append(slug)
            
            logger.info("classification_success", topics=topics, title=title[:50])
            return topics
            
        except Exception as e:
            logger.error("classification_error", error=str(e), title=title[:50])
            return []  # Fallback handled by caller
```

### Int√©gration au Sync Service

```python
# app/services/sync_service.py

class SyncService:
    def __init__(self, session: AsyncSession):
        self.session = session
        self.classification_service = ClassificationService()  # Init lors du startup
    
    async def sync_rss_feed(self, source: Source):
        # ... existing RSS parsing logic
        
        for entry in feed.entries:
            content = Content(
                source_id=source.id,
                title=entry.title,
                description=entry.description,
                # ...
            )
            
            # Classification ML (non-bloquante)
            try:
                topics = self.classification_service.classify(
                    content.title,
                    content.description or ""
                )
                content.topics = topics if topics else source.granular_topics  # Fallback
            except Exception as e:
                logger.warning("ml_classification_failed", error=str(e))
                content.topics = source.granular_topics  # Fallback h√©ritage
            
            self.session.add(content)
        
        await self.session.flush()
```

### Nouvelle ArticleTopicLayer

```python
# app/services/recommendation/layers/article_topic.py

from app.services.recommendation.scoring_engine import BaseScoringLayer, ScoringContext
from app.models.content import Content

class ArticleTopicLayer(BaseScoringLayer):
    """Scoring granulaire bas√© sur les topics d'article."""
    
    @property
    def name(self) -> str:
        return "article_topic"
    
    def score(self, content: Content, context: ScoringContext) -> float:
        score = 0.0
        
        if not content.topics:
            return 0.0
        
        # R√©cup√©rer user_subtopics depuis context
        user_subtopics = context.user_subtopics  # Set[str]
        
        # Matching
        matched_topics = set(content.topics) & user_subtopics
        
        if matched_topics:
            # +40 pts par topic match√©, max 2 topics
            match_count = min(len(matched_topics), 2)
            match_score = match_count * 40.0
            score += match_score
            
            context.add_reason(
                content.id, 
                self.name, 
                match_score, 
                f"Topics pr√©cis: {', '.join(list(matched_topics)[:2])}"
            )
        
        return score
```

### Ajout au ScoringEngine

```python
# app/services/recommendation_service.py

from app.services.recommendation.layers.article_topic import ArticleTopicLayer

class RecommendationService:
    def __init__(self, session: AsyncSession):
        self.session = session
        self.scoring_engine = ScoringEngine([
            CoreLayer(),
            StaticPreferenceLayer(),
            BehavioralLayer(),
            QualityLayer(),
            VisualLayer(),
            ArticleTopicLayer()  # ‚Üê NOUVEAU
        ])
```

### Mise √† jour ScoringContext

```python
# app/services/recommendation/scoring_engine.py

class ScoringContext:
    def __init__(
        self,
        user_profile: UserProfile,
        user_interests: Set[str],
        user_interest_weights: Dict[str, float],
        followed_source_ids: Set[UUID],
        user_prefs: Dict[str, Any],
        user_subtopics: Set[str],  # ‚Üê NOUVEAU
        now: datetime.datetime
    ):
        # ...existing fields
        self.user_subtopics = user_subtopics
```

## Testing

### 1. Test Unitaire Classification

```python
# tests/test_classification_service.py

def test_classification_ai_article():
    service = ClassificationService()
    
    title = "ChatGPT-5 annonc√© par OpenAI"
    description = "La nouvelle version du mod√®le de langage..."
    
    topics = service.classify(title, description)
    
    assert "ai" in topics or "llm" in topics
    assert len(topics) <= 5
```

### 2. √âchantillon Test (Annotation Manuelle)

```python
# scripts/create_test_sample.py

# Annoter manuellement 100 articles vari√©s
test_sample = [
    {
        "title": "La COP28 se cl√¥t sur un accord historique",
        "description": "...",
        "expected_topics": ["climate", "international"]
    },
    # ... 99 autres
]

# Mesurer pr√©cision
def evaluate_accuracy():
    service = ClassificationService()
    correct = 0
    
    for sample in test_sample:
        predicted = service.classify(sample['title'], sample['description'])
        expected = set(sample['expected_topics'])
        
        # Score : Intersection / Union (Jaccard)
        if set(predicted) & expected:  # Au moins 1 match
            correct += 1
    
    accuracy = correct / len(test_sample)
    assert accuracy > 0.80, f"Accuracy trop faible: {accuracy}"
```

### 3. Test Fallback H√©ritage

```python
# tests/test_sync_with_classification.py

async def test_fallback_on_ml_failure(monkeypatch):
    """V√©rifie que si ML √©choue, articles h√©ritent granular_topics."""
    
    # Mock classification failure
    def failing_classify(*args, **kwargs):
        raise Exception("ML service down")
    
    monkeypatch.setattr(ClassificationService, "classify", failing_classify)
    
    source = Source(theme="tech", granular_topics=["ai", "crypto"])
    # ... sync article
    
    assert content.topics == ["ai", "crypto"]  # H√©ritage
```

## Performance & Scalability

### Railway Configuration

```yaml
# railway.json (update)

services:
  - name: api
    env:
      ML_ENABLED: true
    memory: 768  # +200MB pour mod√®le (√©tait 512)
```

### Monitoring

```python
# Ajouter metrics
import time

def classify_with_metrics(self, title, description):
    start = time.time()
    topics = self.classify(title, description)
    duration = time.time() - start
    
    logger.info("classification_performance", 
                duration_ms=duration*1000, 
                topics_count=len(topics))
    
    return topics
```

## Effort & Priority

- **Effort :** 13 points (1 sprint)
- **Priority :** üü° HIGH
- **Sprint :** +2

## Dependencies

- **Bloqu√© par :** Story 4.1c (taxonomie doit exister)
- **Bloque :** Story 8.3-8.6 (progression d√©pend de topics pr√©cis)

## Risks & Mitigation

| Risque | Probabilit√© | Impact | Mitigation |
|--------|-------------|--------|------------|
| RAM > 300MB | Moyen | Co√ªt Railway | Monitorer, downgrade mod√®le si besoin |
| Pr√©cision < 80% | Faible | UX | Fine-tuning ou r√®gles hybrides |
| Latence > 500ms | Faible | Sync lent | Async + timeout |

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 19/01/2026 | 1.0 | Initial Draft | Antigravity |
