---
phase: 01-foundation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/api/app/services/digest_selector.py
  - packages/api/app/services/digest_selector_test.py
  - packages/api/app/jobs/digest_generation_job.py
  - packages/api/app/jobs/__init__.py
autonomous: true

must_haves:
  truths:
    - "DigestSelector service selects exactly 5 articles from user sources"
    - "Diversity constraints enforced: max 2 per source, max 2 per theme"
    - "Fallback to curated sources when user pool < 5 articles"
    - "Service reuses existing ScoringEngine without modifications"
  artifacts:
    - path: "packages/api/app/services/digest_selector.py"
      provides: "DigestSelector service with select_for_user method"
      exports: ["DigestSelector", "DigestItem"]
      min_lines: 150
    - path: "packages/api/app/services/digest_selector_test.py"
      provides: "Unit tests for digest selection logic"
      exports: ["test_diversity_constraints", "test_fallback_sources"]
    - path: "packages/api/app/jobs/digest_generation_job.py"
      provides: "Daily job to generate digests for all users"
      exports: ["run_digest_generation"]
  key_links:
    - from: "DigestSelector"
      to: "ScoringEngine"
      via: "scoring_engine.compute_score()"
      pattern: "scoring_engine\.compute_score"
    - from: "DigestSelector"
      to: "PersonalizationLayer"
      via: "respect existing muted sources/themes/topics"
      pattern: "context\.muted_sources"
---

<objective>
Create DigestSelector service for intelligent 5-article digest generation.

Purpose: Implement the core selection algorithm for Epic 10's digest-first experience, ensuring diversity constraints and fallback mechanisms while reusing existing scoring infrastructure.

Output:
- DigestSelector service class with select_for_user method
- Unit tests for selection logic
- Daily generation job for batch processing
</objective>

<execution_context>
@/Users/laurinboujon/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Users/laurinboujon/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md

# Existing services to reuse
@packages/api/app/services/briefing_service.py
@packages/api/app/services/recommendation_service.py
@packages/api/app/services/streak_service.py

# Scoring engine reference
@packages/api/app/services/recommendation/scoring_engine.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DigestSelector service</name>
  <files>packages/api/app/services/digest_selector.py</files>
  <action>
Create DigestSelector service that selects 5 articles per user following diversity constraints.

Service Structure (packages/api/app/services/digest_selector.py):

1. Dataclasses/Types:
   - DigestItem: content (Content), rank (int), score (float), reason (str), source_id (UUID), theme (str)
   - SelectionConstraints: max_per_source (int=2), max_per_theme (int=2)

2. DigestSelector class:
   - __init__(self, session: AsyncSession)
   - select_for_user(user_id: UUID, target_count: int = 5) -> List[DigestItem]

3. Selection Algorithm (in select_for_user):
   A. Get candidate pool:
      - Query articles from user's declared sources (36h window)
      - Use _get_candidates() pattern from briefing_service.py
   
   B. Score candidates:
      - Initialize RecommendationService(self.session)
      - Create ScoringContext using existing pattern
      - Score each candidate: scored = [(content, score), ...]
   
   C. Apply diversity constraints:
      - Sort by score descending
      - Initialize: selected = [], source_counts = {}, theme_counts = {}
      - For each candidate in scored order:
        - Check source constraint: source_counts[source_id] < 2
        - Check theme constraint: theme_counts[theme] < 2
        - If passes both constraints: add to selected
        - Stop when len(selected) == 5
   
   D. Fallback mechanism:
      - If len(selected) < 5:
        - Fetch from curated sources (same scoring, no personalization penalty)
        - Apply same diversity constraints
        - Complete until 5 or no more candidates
   
   E. Return DigestItem list with ranks 1-5

4. Helper methods:
   - _get_user_sources(user_id) -> Set[UUID]
   - _get_candidates(user_id, limit, followed_source_ids) -> List[Content]
   - _apply_diversity_constraints(scored, target_count) -> List[DigestItem]
   - _get_curated_sources() -> List[Source] — high-quality curated sources

Key Requirements from REQUIREMENTS.md:
- Reuse existing ScoringEngine WITHOUT modifications
- Query existing user_interests, user_subtopics tables
- Integrate with PersonalizationLayer (muted sources/themes/topics)
- Diversity: max 2 per source, max 2 per theme

Do NOT modify scoring algorithm weights — only selection wrapper.
  </action>
  <verify>
cd packages/api && python -c "from app.services.digest_selector import DigestSelector, DigestItem; print('Import OK')"
# Check no syntax errors:
python -m py_compile packages/api/app/services/digest_selector.py
  </verify>
  <done>
DigestSelector class imports without errors, has select_for_user method, follows existing service patterns
  </done>
</task>

<task type="auto">
  <name>Task 2: Create unit tests for DigestSelector</name>
  <files>packages/api/app/services/digest_selector_test.py</files>
  <action>
Create comprehensive unit tests for DigestSelector diversity and fallback logic.

Test File (packages/api/app/services/digest_selector_test.py):

Use pytest and mock the database/scoring. Focus on:

1. Test diversity constraints:
   - test_max_2_per_source: Mock 10 articles from 3 sources, verify only 2 max from each source
   - test_max_2_per_theme: Mock articles with different themes, verify theme constraint
   - test_diversity_enforced_even_if_lower_score: Verify higher-scored article is skipped if it violates constraint

2. Test fallback to curated sources:
   - test_fallback_when_user_pool_lt_5: User has 3 articles, verify 2 from curated added
   - test_fallback_with_diversity: Verify fallback articles also respect diversity constraints

3. Test integration with personalization:
   - test_muted_sources_excluded: Verify muted sources not in pool
   - test_muted_themes_excluded: Verify muted themes not in pool

4. Test basic functionality:
   - test_returns_exactly_5_articles: Normal case with sufficient pool
   - test_returns_less_than_5_if_no_fallback: Edge case where even curated can't complete
   - test_rank_assignment: Verify ranks 1-5 assigned correctly

Test structure:
- Use pytest fixtures for mock data
- Mock AsyncSession and content objects
- Mock ScoringEngine to return predictable scores
- Do NOT require real database — pure unit tests

Example test pattern:
```python
@pytest.mark.asyncio
async def test_max_2_per_source():
    # Arrange: 6 articles, 3 from source A (scores 100, 90, 80), 3 from source B
    # Act: select_for_user
    # Assert: 2 from A, 2 from B, 1 from next best (respecting theme constraint too)
```
  </action>
  <verify>
cd packages/api && python -m pytest app/services/digest_selector_test.py -v
# All tests should pass (initially they may be skipped if dependencies not ready)
  </verify>
  <done>
At least 5 test functions exist covering diversity, fallback, and personalization
  </done>
</task>

<task type="auto">
  <name>Task 3: Create daily digest generation job</name>
  <files>packages/api/app/jobs/digest_generation_job.py, packages/api/app/jobs/__init__.py</files>
  <action>
Create batch job for daily digest generation at 8am Paris time.

Job File (packages/api/app/jobs/digest_generation_job.py):

1. Main function:
   - run_digest_generation(db: AsyncSession, target_date: date = None)
   - If target_date is None, use today (Paris timezone: Europe/Paris)

2. Job flow:
   - Query all active users
   - For each user:
     - Check if digest already exists for date (skip if yes, idempotent)
     - Call DigestSelector.select_for_user() to get 5 articles
     - If selection successful:
       - Create DailyDigest record with items JSONB
       - items format: [{"content_id": str, "rank": int, "reason": str, "action": "unread"}, ...]
       - Save to daily_digest table
   - Log progress: "Generated digests: X users, Y failed"

3. Scheduling integration:
   - Export run_digest_generation as the entry point
   - Document how to schedule via Railway cron or APScheduler
   - Target: 8:00 AM Europe/Paris daily

4. Error handling:
   - Catch exceptions per user (don't stop batch on one failure)
   - Log failures with user_id and error
   - Continue processing remaining users

5. Performance:
   - Process users in batches (chunk size: 100)
   - Commit after each batch
   - Use tqdm or logging for progress indication

Update packages/api/app/jobs/__init__.py to export:
- from .digest_generation_job import run_digest_generation

Reference existing job pattern: Look at how top3_job.py works in production.
  </action>
  <verify>
cd packages/api && python -c "from app.jobs.digest_generation_job import run_digest_generation; print('Import OK')"
python -m py_compile packages/api/app/jobs/digest_generation_job.py
cd packages/api && python -c "from app.jobs import run_digest_generation; print('Export OK')"
  </verify>
  <done>
Job imports without errors, has main function run_digest_generation, documented schedule target
  </done>
</task>

</tasks>

<verification>
1. DigestSelector service imports and has select_for_user method
2. Unit tests cover diversity constraints and fallback scenarios
3. Daily generation job has entry point function with proper error handling
4. All code follows existing patterns (briefing_service, recommendation_service)
5. No modifications to ScoringEngine (verified by import without changes)
6. Service integrates with DailyDigest model from Plan 01-01
</verification>

<success_criteria>
- DigestSelector.select_for_user() returns exactly 5 articles (or fewer if insufficient pool + fallback)
- Diversity constraints enforced: ≤2 per source, ≤2 per theme
- Fallback to curated sources when user pool < 5
- Reuses existing ScoringEngine without modifications
- Unit tests pass for core selection logic
- Daily generation job can be scheduled (documented 8am Paris target)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
